{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb30d1de",
   "metadata": {},
   "source": [
    "<img src=\"./resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">DAY 3 Workshop SWDB 2025 </h1> \n",
    "<h3 align=\"center\">Wednesday, August 27th, 2025</h3> \n",
    "<h3 align=\"center\">How does network dynamics govern behavior?</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2052acfc",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "<h2>Objectives</h2>\n",
    "    \n",
    "<p>By the end of this lesson, you will be able to\n",
    "\n",
    "<p>-Think about physical and biological systems in terms of states and dynamical systems\n",
    "<p>-Visualize the network state evolution of a recurrent neural network (RNN)\n",
    "<p>-Identify the linear dynamics around fixed points\n",
    "<p>-Think critically about the dynamical systems that implement various tasks\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e4888",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>The Origins of Dynamics: </h2> \n",
    "<p>from Steve Strogatz, Nonlinear Dynamics and Chaos 2018\n",
    "<p>Although dynamics is an interdisciplinary subject today, it was originally a branch of physics. The subject began in the mid-1600s, when Newton invented differential equations, discovered his laws of motion and universal gravitation, and combined them to explain Kepler's laws of planetary motion. Specifically, Newton solved the two-body problem—the problem of calculating the motion of the earth around the sun, given the inverse-square law of gravitational attraction between them.\n",
    "\n",
    "<p>Subsequent generations of mathematicians and physicists tried to extend Newton's analytical methods to the three-body problem (e.g., sun, earth, and moon) but curiously this problem turned out to be much more difficult to solve. After decades of effort, it was eventually realized that the three-body problem was essentially impossible to solve, in the sense of obtaining explicit formulas for the motions of the three bodies. At this point the situation seemed hopeless.\n",
    "\n",
    "<p>The invention of the high-speed computer in the 1950s was a watershed in the history of dynamics. The computer allowed one to experiment with equations in a way that was impossible before, and thereby to develop some intuition about nonlinear systems. Such experiments led to Lorenz’s discovery in 1963 of chaotic motion on a strange attractor, which may have a familiar shape.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5470dd",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### Lorenz Attractor\n",
    "*The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. This chaotic system is completely deterministic and yet inherently unpredictable over long periods of time.*\n",
    "\n",
    "<img src=\"./resources/lorenz.png\" alt=\"Foraging Task Schematic\" width=600>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e21934",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Dynamical Systems in Biology </h2> \n",
    "<p> As discussed in the lecture, a dynamical system is one that changes in time. There are often inputs to the system that shape how the state of the system changes in time. Fundamental to thinking about biological systems as dynamical systems is identifying a 'state' of the system that changes in time, and whatever inputs are the relevant ones that might change the way the state evolves in time. At a high level, it's very intuitive to think about how biological systems can be interpretted as having a state. You can be hungry, happy, angry or sad - and that might effect the way you interact with your environment. At a more microscopic level, you can also think about the conformational state of a protein that might change how it interacts with the environment and which other molecules it might form bonds with. In systems neuroscience, we often think of neural activity in terms of the activity rate of all the neurons that we record. Using this framework for thinking about the brain as a dynamical system, we can study how neural computation might be implemented through a dynamical system.\n",
    "    \n",
    "<p>In this tutorial, we will discuss dynamical systems in the context of computation and behavior. We will reverse engineer the dynamics of recurrent neural networks (RNNs) trained to solve a foraging task using reinforcement learning. At the end, we extrapolate to thinking about the dynamics for various neuroscience tasks.\n",
    "\n",
    "<p>Through this analysis, we hope to gain a better understanding of how RNNs can solve complex sequential decision-making problems and potentially uncover general principles underlying their computational capabilities that will lead to hypotheses about how brains might implement the same task.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d293734",
   "metadata": {},
   "source": [
    "<!-- # Understanding neural circuit and dynamics with recurrent neural networks\n",
    "(First draft: Po-Chen Kuo 06.21.2024)\n",
    "- task trained RNNs\n",
    "- actor-critic RNNs solving dynamic foraging\n",
    "- visualize RNN acticities using PCA\n",
    "- dynamical systems analysis of RNN -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7128c67b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Task-trained RNNs with Reinforcement Learning</h2>\n",
    "<p> Task-driven RNNs are trained to take in a set of inputs and produce corresponding outputs that were designed to match cognitive tasks that animals are trained to perform. This approach is utilized to generate hypotheses about how dynamical systems implement the task of interest. Through in depth analysis of task-trained RNNs, researchers can develop a hypotheses about possible mechanisms that may be used in the brain to implement the same task. \n",
    "        \n",
    "<p>Task-trained RNNs can be combined with reinforcement learning (RL) techniques to model how neural systems learn to perform tasks through interaction with their environment. Two popular RL methods used with RNNs are:\n",
    "\n",
    "<p>Policy Gradient Method: This is a type of RL algorithm that directly optimizes the policy (the strategy for choosing actions) to maximize expected rewards. Key features include learning a probability distribution over actions, updating policy parameters in the direction of higher rewards, and being well-suited for continuous action spaces and partially observable environments. In the context of RNNs, the output can represent action probabilities. The hidden state can maintain information about past observations. Backpropagation through time is often used to compute gradients.\n",
    "\n",
    "<p>Actor-Critic Algorithm: This is an advanced RL method that combines elements of both policy-based and value-based learning. It consists of an Actor, which learns the policy (which actions to take), and a Critic, which learns to estimate the value function (how good the current state is). Key features include reduced variance in policy updates compared to pure policy gradient methods, ability to learn in continuous action spaces, and often more stability and sample-efficiency than pure policy gradient methods. In the context of RNNs, the network can be split into two parts for the actor and critic, with the actor part outputting action probabilities and the critic part estimating state values. Both parts can share lower-level features.\n",
    "\n",
    "<p>These RL techniques allow task-trained RNNs to learn complex behaviors over time, mimicking how biological neural systems might learn through experience and reward signals.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b69dd",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Dynamic Foraging: Two Armed Bandit Task </h2>\n",
    "<p> We will model a two-armed bandit task, that scientists at the Allen Institute for Neural Dynamics are currently training mice to perform. In this task, mice must choose to lick either a left or right lick port. The probability of reward in either arm changes over time. One side is rewarded with a probability of 20% and the other side is rewarded 80% for a given block. Blocks are randomly switched with a Guassian distribution centered on 40 trials.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f2777c",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<img src=\"./resources/dyn_foraging_task_schematic.png\" alt=\"Foraging Task Schematic\" width=600>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39788c50",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Actor-critic RNNs solving dynamic foraging</h2>\n",
    "<p>As our goal in this tutorial is to analyze RNN circuit and dynamics, here we provide RNNs readily trained to solve the dynamic foraging task. \n",
    "\n",
    "<p>We will first look at the behavior of the network from example sessions.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf7ae9",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## 1. Load and visualize data\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3fc1c",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Main imports:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf9483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ac9f3",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "On each trial, the RNN receives the action (0/1 indicating left/right) and reward (0 or 1) from the previous trial as input, integrates this input with its hidden states, and generates an action (0/1 indicating left/right) as output\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9f5fc9",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Define hyperparameters:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dim = 2\n",
    "total_trials = 400\n",
    "rnn_hidden_dim = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855dbf50",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Load example sessions:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/info_testing_set.pickle', 'rb') as f:\n",
    "    info_testing_set = pickle.load(f)\n",
    "\n",
    "actions_testing_set = np.load('./data/actions_testing_set.npy')\n",
    "rewards_testing_set = np.load('./data/rewards_testing_set.npy')\n",
    "a1_probs_testing_set = np.load('./data/a1_probs_testing_set.npy')\n",
    "actor_hidden_states_testing_set = np.load('./data/actor_hidden_states_testing_set.npy', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d7f94",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Select the first example session:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_session_id = 1\n",
    "info = info_testing_set[example_session_id]\n",
    "actions = actions_testing_set[example_session_id]\n",
    "rewards = rewards_testing_set[example_session_id]\n",
    "a1_probs = a1_probs_testing_set[example_session_id]\n",
    "actor_hidden_states = actor_hidden_states_testing_set[example_session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68762ab0",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Plot the behavior from example session:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9bf30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shading_blocks(ax, info):\n",
    "\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    block_start = 0\n",
    "    for block_ind in range(len(info['block_lens'])):\n",
    "        if block_ind % 2 == 1:\n",
    "            ax.fill_between(\n",
    "                [block_start, block_start+info['block_lens'][block_ind]],\n",
    "                y_min, y_max,\n",
    "                color='gray', alpha=0.2\n",
    "            )\n",
    "        block_start += info['block_lens'][block_ind]\n",
    "\n",
    "        \n",
    "fig, ax = plt.subplots(1,1, figsize=(6, 3), dpi=150)\n",
    "ax.set_title(f'Behavior of the trained RNN')\n",
    "\n",
    "# event raster\n",
    "events = []\n",
    "for act in range(action_dim):\n",
    "    # 0: action 0, 1: action 1\n",
    "    for rew in [0, 1]:\n",
    "        events_act_rew = np.where(\n",
    "            (actions==act) & (rewards==rew))[0]\n",
    "        events.append(events_act_rew)\n",
    "line_offsets = [-0.3,-0.3] + [1.3,1.3]\n",
    "line_lengths = [0.2,0.4] + [0.2,0.4]\n",
    "ax.eventplot(events, lineoffsets=line_offsets, \n",
    "            linelengths=line_lengths, linewidth=1)\n",
    "\n",
    "# action running average\n",
    "running_average_window = 10\n",
    "actions_moving_average = np.convolve(\n",
    "    np.array(actions), np.ones(running_average_window), mode=\"same\") \\\n",
    "        / running_average_window\n",
    "ax.plot(\n",
    "    np.arange(len(actions_moving_average)), \n",
    "    actions_moving_average\n",
    ")\n",
    "\n",
    "# block reward prob: action 1 \n",
    "# get blocks\n",
    "rew_prob_a1 = []\n",
    "for block_idx, block_len in enumerate(info['block_lens']):\n",
    "    for trial_idx in range(block_len):\n",
    "        rew_prob_a1.append(info['reward_prob'][block_idx][1])\n",
    "block_reward_prob_color = 'k'\n",
    "            \n",
    "ax.plot(\n",
    "    np.arange(len(rew_prob_a1)),\n",
    "    rew_prob_a1, \n",
    "    c=block_reward_prob_color\n",
    ")\n",
    "shading_blocks(ax, info)\n",
    "\n",
    "ax.set_xlabel('Trial')\n",
    "ax.set_ylabel('Action probability')\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_yticklabels(['Left (0)', 'Right (1)'])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efee11c",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Plot the output: policy or action probability:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ee0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(6, 2), dpi=150)\n",
    "ax.set_title(f'Policy of the trained RNN: P(action= right choice)')\n",
    "\n",
    "colors = ['b']\n",
    "\n",
    "arr = a1_probs\n",
    "ax.plot(np.arange(len(arr)), arr, label='prob_a1', color=colors[0])\n",
    "\n",
    "ax.set_xlabel('Trial')\n",
    "ax.set_ylabel('P(action = right choice)')\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "shading_blocks(ax, info)\n",
    "\n",
    "# block reward prob: action 1\n",
    "ax = ax.twinx()\n",
    "ax.plot(\n",
    "    np.arange(len(rew_prob_a1)),\n",
    "    rew_prob_a1, \n",
    "    c=block_reward_prob_color\n",
    ")\n",
    "ax.set_ylabel('P(reward = right)', c=block_reward_prob_color)\n",
    "ax.tick_params(axis='y', labelcolor=block_reward_prob_color)\n",
    "ax.set_ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49a7f5b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Plot RNN activity (activities of example individual units):*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22accd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_units_plot = 5\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6, 2), dpi=150)\n",
    "ax.set_title(f'Neural activities of the trained RNN')\n",
    "\n",
    "for plot_id in range(n_hidden_units_plot):\n",
    "    arr = actor_hidden_states[:, plot_id]\n",
    "    ax.plot(arr, lw=0.9, label=f'neuron {plot_id}')\n",
    "\n",
    "shading_blocks(ax, info)\n",
    "\n",
    "ax.set_xlabel('Timestep')\n",
    "ax.set_ylabel('Actor hidden state')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad744e",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "* **Exercise:** plot the above for another session \n",
    "* **Discussion:** what's the difference between each session?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b368050",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## 2. Visualize RNN activities using PCA\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915ff25",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "To better visualize and understand network dynamics of the trained network, we can apply dimensionality reduction methods to extract relevant dimensions within the high-dimensional neural activity space. \n",
    "One example method is principal component analysis (PCA), which captures the dimensions that explain the most variances within our dataset.\n",
    "\n",
    "<img src=\"./resources/pca.png\" alt=\"PCA\" width=1500>\n",
    "\n",
    "(Ref: Pang, R., Lansdell, B. J., & Fairhall, A. L. (2016). Dimensionality reduction in neuroscience. Current Biology, 26(14), R656-R660.)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c727de",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Load training set:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/info_training_set.pickle', 'rb') as f:\n",
    "    info_training_set = pickle.load(f)\n",
    "\n",
    "actions_training_set = np.load('./data/actions_training_set.npy')\n",
    "rewards_training_set = np.load('./data/rewards_training_set.npy')\n",
    "a1_probs_training_set = np.load('./data/a1_probs_training_set.npy')\n",
    "actor_hidden_states_training_set = np.load('./data/actor_hidden_states_training_set.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af06bc0e",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "**Quick check:** how many sessions do we have in the training set?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7d011",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Perform PCA on the training set:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d854cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "num_components = 8\n",
    "\n",
    "pca_model_actor = PCA(n_components=num_components)\n",
    "transformed_actor_hidden_states_training_set = pca_model_actor.fit_transform(actor_hidden_states_training_set.reshape(-1, rnn_hidden_dim)).reshape(\n",
    "    -1, total_trials, num_components)\n",
    "\n",
    "print(f'PCA explained variance: {pca_model_actor.explained_variance_ratio_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bd9fe3",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Plot variance explained by the top principal components (individual and cumulative):*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b2040",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(8, 3), dpi=150)\n",
    "\n",
    "ax = axs[0]\n",
    "ax.plot(np.arange(1, len(pca_model_actor.explained_variance_ratio_)+1), pca_model_actor.explained_variance_ratio_)\n",
    "ax.set_title('Actor variance explained per PC')\n",
    "ax.set_xlabel('PC')\n",
    "ax.set_ylabel('Variance explained')\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(np.hstack(([0], np.cumsum(pca_model_actor.explained_variance_ratio_))))\n",
    "ax.set_title('Actor cumulative variance explained')\n",
    "ax.set_xlabel('Number of PCs')\n",
    "ax.set_ylabel('cumulative variance explained')\n",
    "ax.set_ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478f9b4",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Visualize network activity projected into the first two PCs:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c039fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(5,4), dpi=150)\n",
    "\n",
    "pc_x = 0\n",
    "pc_y = 1\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    transformed_actor_hidden_states_training_set[:, :, pc_x],\n",
    "    transformed_actor_hidden_states_training_set[:, :, pc_y],\n",
    "    s=3.0,\n",
    "#   c=VAR_TO_COLOR, \n",
    "#   cmap=cm.coolwarm,\n",
    "#   vmin=0, \n",
    "#    vmax=1,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(f'PC {pc_x+1}')\n",
    "ax.set_ylabel(f'PC {pc_y+1}')\n",
    "# cb = fig.colorbar(scatter, ax=ax, label = 'VAR_TO_COLOR')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe88e7",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**Exercise:** uncomment the lines and modify the code above to color the scatter plot according to relevant task variables. Variables to try: `rewards_training_set` (reward outcome), `actions_training_set` (action outcome), `a1_probs_training_set` (action probability). \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677b4dc",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Let us see how a single test episode unfolds. Note that here we use the session loaded above (defined by `example_session_id`).\n",
    "\n",
    "*Visualize a test episode by projecting its neural activity into the first two PCs calculated using training data set:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the test set first\n",
    "transformed_actor_hidden_states_testing_set = pca_model_actor.transform(\n",
    "    actor_hidden_states_training_set.reshape(-1, rnn_hidden_dim))\n",
    "transformed_actor_hidden_states_testing_set = transformed_actor_hidden_states_testing_set.reshape(\n",
    "    -1, total_trials, num_components)\n",
    "\n",
    "# how many steps to visualize\n",
    "trial_end = 60\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,4), dpi=200)\n",
    "\n",
    "pc_x = 0\n",
    "pc_y =1\n",
    "\n",
    "# plot all trials\n",
    "scatter = ax.scatter(\n",
    "    transformed_actor_hidden_states_training_set[:, :, pc_x],\n",
    "    transformed_actor_hidden_states_training_set[:, :, pc_y],\n",
    "    s=3.0,\n",
    "    c=a1_probs_training_set, cmap=cm.coolwarm,\n",
    "    vmin=0, vmax=1,\n",
    ")\n",
    "fig.colorbar(scatter, ax=ax, label = 'P(action = right choice)')\n",
    "\n",
    "# plot example run\n",
    "ax.plot(\n",
    "    transformed_actor_hidden_states_testing_set[example_session_id, :trial_end, pc_x],\n",
    "    transformed_actor_hidden_states_testing_set[example_session_id, :trial_end, pc_y],\n",
    "    color='k', alpha=0.8, lw=1\n",
    ")\n",
    "example_run = ax.scatter(\n",
    "    transformed_actor_hidden_states_testing_set[example_session_id, :trial_end, pc_x],\n",
    "    transformed_actor_hidden_states_testing_set[example_session_id, :trial_end, pc_y],\n",
    "    s=10,\n",
    "    c=np.arange(trial_end), cmap=cm.copper,\n",
    "    vmin=0, vmax=trial_end\n",
    ")  # color coded by time step\n",
    "fig.colorbar(\n",
    "    example_run, ax=ax,\n",
    "    label='Time step'\n",
    ")\n",
    "\n",
    "ax.set_xlabel(f'PC {pc_x+1}')\n",
    "ax.set_ylabel(f'PC {pc_y+1}')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996421ec",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**Exercises:** \n",
    "* Play with the `trial_end` parameter above, explore how the RNN activities evolve in the PC space.\n",
    "* Visualize activity projected onto other PCs, what do you find?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b58af",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Create an animation:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497136d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import imageio\n",
    "import io\n",
    "import os\n",
    "from utils import create_frame\n",
    "\n",
    "import platform\n",
    "\n",
    "if 'amzn2' in platform.platform():\n",
    "    DIR_RESULTS = '/results'    # use within the capsule\n",
    "else:\n",
    "    DIR_RESULTS = '.'           # use to store files within the same directory instead\n",
    "\n",
    "# Create frames\n",
    "def make_mov(n_frames=360, azim_start=60, axes_set=[0,1,2]):\n",
    "    frames = []\n",
    "    fig = plt.figure(figsize=(10, 8), dpi=150)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    for i in range(n_frames):\n",
    "        # Clear the previous frame\n",
    "        ax.clear()\n",
    "\n",
    "        # Calculate elevation and azimuth for this frame\n",
    "        elev = 30 + 30 * np.sin(2 * np.pi * i / 360)\n",
    "        azim = azim_start + 360 * i / 360  # Full 360 degree rotation\n",
    "\n",
    "        # Create the frame\n",
    "        buf = create_frame(transformed_actor_hidden_states_training_set, transformed_actor_hidden_states_testing_set, \n",
    "                           a1_probs_training_set, example_session_id, elev, azim, axes_set=axes_set, frame=i)\n",
    "        frame = imageio.v2.imread(buf)\n",
    "        frames.append(frame)\n",
    "\n",
    "        # Update progress\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processed frame {i}/{n_frames}\")\n",
    "\n",
    "    # Save as GIF\n",
    "    axes_set_str = '_'.join(str(x) for x in axes_set)\n",
    "    dir_mov = os.path.join(DIR_RESULTS, 'movs')\n",
    "    os.makedirs(dir_mov, exist_ok=True)\n",
    "    path_mov = os.path.join(dir_mov, f'rotating_3d_plot_2rotationaxes{axes_set_str}.gif')\n",
    "    imageio.mimsave(path_mov, frames, fps=5)\n",
    "\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b458af",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mov(n_frames = 60, azim_start = 0, axes_set = [0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c67a1",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "The animation should be available in `/results/movs/`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fe13f6",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## 3. Dynamical systems analysis of RNN\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c912aa",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### Finding approximate fixed points\n",
    "Here we aim to find approximate fixed points. For a given dynamical system (e.g. the trained RNN),\n",
    "\\begin{align}\n",
    "    \\frac{d\\mathbf{x}}{dt} = F(\\mathbf{x}),\n",
    "\\end{align}\n",
    "\n",
    "We can find approximated fixed points by minimizing the kinetic energy of the system, $q$.\n",
    "\\begin{align}\n",
    "    \\mathrm{argmin}_{\\mathbf{x}}  q = \\frac{1}{2} (F(\\mathbf{x}))^2.\n",
    "\\end{align}\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065b865",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Because there are five different input conditions (prev_action, prev_reward) for our task: null, (0, 1), (0, 0), (1, 0), (1, 1), we can find fixed points of the trained RNN under these conditions respectively. To empirically identify fixed points, initialize along the trajectory of the network state and move down the gradient of the q value, defined above. Save approximate fixed point locations once they meet a pre-defined q threshold. Here, we provide pre-computed fixed points, computed with `q_threshold=0.001`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e05de",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Load the pre-computed fixed points:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaffaeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps_path = './data/df_fps_dict_250718.pickle'\n",
    "with open(fps_path, 'rb') as f:\n",
    "    df_fps_per_condition = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5c998",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Visualize the fixed points under different input conditions in the PC space:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b379de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input condition\n",
    "# (0,1) labeled 0+\n",
    "# (0,0) labeled 0-\n",
    "# (1,1) labeled 1+\n",
    "# (1,0) labeled 1-\n",
    "# 'null': no action, no reward\n",
    "\n",
    "# set a q_threshold to select fixed points with q smaller than the threshold\n",
    "q_threshold = .00001\n",
    "\n",
    "for condition in ['0+', '0-', '1+', '1-', 'null']:\n",
    "    df_select = df_fps_per_condition[condition]\n",
    "    \n",
    "    # filter by q_threshold\n",
    "    df_select = df_select[df_select['q_star'] <= q_threshold].sort_values(by='q_star')\n",
    "    qstar = df_select['q_star'].values\n",
    "    \n",
    "    # transform the fixed points\n",
    "    fixed_points = df_select['x_star'].values\n",
    "    fixed_points = np.vstack(fixed_points[:]).astype(float)  # convert object arr to float arr\n",
    "    transformed_fixed_points = pca_model_actor.transform(\n",
    "        fixed_points.reshape(-1, rnn_hidden_dim))\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(\n",
    "        nrows=1, ncols=1, figsize=(6, 4.5), dpi=200)\n",
    "\n",
    "    # plot the first 2 PCs\n",
    "    pc_x = 0\n",
    "    pc_y = 1\n",
    "\n",
    "    ax.set_title(f'Fixed points for {condition}', fontsize=18)\n",
    "    scatter = ax.scatter(\n",
    "        transformed_actor_hidden_states_training_set[:, :, pc_x],\n",
    "        transformed_actor_hidden_states_training_set[:, :, pc_y],\n",
    "        c=a1_probs_training_set, cmap=cm.coolwarm,\n",
    "        vmin=0, vmax=1, s=2, alpha=0.7\n",
    "    )\n",
    "    scatter_fp = ax.scatter(\n",
    "        transformed_fixed_points[:, pc_x],\n",
    "        transformed_fixed_points[:, pc_y],\n",
    "        marker='*', \n",
    "        s=200,\n",
    "        # color='k', \n",
    "        c=qstar, cmap=cm.gray,\n",
    "        vmin=1e-13, vmax=1, norm='log',\n",
    "    )\n",
    "    ax.set_xlabel(f'PC {pc_x+1}', fontsize=18)\n",
    "    ax.set_ylabel(f'PC {pc_y+1}', fontsize=18)\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    fig.colorbar(scatter, ax=ax, label = 'P(action = right choice)')\n",
    "    fig.colorbar(scatter_fp, ax=ax, label = 'Kinetic Energy (q value)')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72050c65",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## 4. Linear Dynamical Systems Analysis\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791835b7",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### Linear dynamical systems analysis\n",
    "*Stability of a fixed point can be characterized as stable, saddle, or unstable, based on the real part of its Jacobian eigenvalue.*\n",
    "\n",
    "<img src=\"./resources/linear_stability_analysis.png\" alt=\"Linear stability analysis\" width=900>\n",
    "\n",
    "(See Reading section for the mathematical details)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfd379b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Visualize fixed points and their Jacobian eigenvalues:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5157174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import comp_eig_decomp, plot_FPs\n",
    "\n",
    "for condition in ['0+', '0-', '1+', '1-', 'null']:\n",
    "    \n",
    "    # filter by q_threshold\n",
    "    \"\"\"This section filters the dataframe df_fps_per_condition to select the fixed point \n",
    "    with the smallest q_star value for the current condition.\"\"\"\n",
    "    \n",
    "    df_sorted = df_fps_per_condition[condition].sort_values(by=['q_star'], ascending=True)\n",
    "    # df_select = df_sorted.iloc[[pre_identified_fixed_points[condition],]]\n",
    "    df_select = df_sorted.iloc[:10]\n",
    "    qstar = df_select['q_star'].values\n",
    "    \n",
    "    # transform the fixed points\n",
    "    \"\"\"The fixed points are converted to a floating-point array and then projected \n",
    "    into a lower-dimensional space using PCA. This transformation helps in visualizing \n",
    "    the fixed points in a reduced feature space.\"\"\"\n",
    "    \n",
    "    fixed_points = df_select['x_star'].values\n",
    "    fixed_points = np.vstack(fixed_points[:]).astype(float)  # convert object arr to float arr\n",
    "    transformed_fixed_points = pca_model_actor.transform(\n",
    "        fixed_points.reshape(-1, rnn_hidden_dim))\n",
    "    \n",
    "    # get Jacobians eigendecomposition\n",
    "    \"\"\"This segment extracts Jacobian matrices, reshapes them, and performs an \n",
    "    eigendecomposition. The eigenvalues are crucial for understanding the stability \n",
    "    of the fixed points; eigenvalues inside the unit circle will indicate stability in \n",
    "    a discrete dynamical system.\"\"\"\n",
    "    \n",
    "    fp_Jacs = df_select['x_star_jac'].T.values\n",
    "    fp_Jacs = np.vstack(fp_Jacs[:]).astype(float)  # convert object arr to float arr\n",
    "    fp_Jacs = fp_Jacs.reshape(-1, rnn_hidden_dim, rnn_hidden_dim)\n",
    "\n",
    "    eig_decomps = comp_eig_decomp(fp_Jacs, sort_by='real',do_compute_lefts=True)\n",
    "\n",
    "    \n",
    "    # plot\n",
    "    \"\"\"A figure with two subplots is created.\n",
    "    \n",
    "    Plot 1: The first subplot displays the fixed points and the expanding \n",
    "    dimensions in the PCA-transformed space. Points are color-coded based on \n",
    "    the probability of a particular outcome (e.g., \"Right Lick\").\n",
    "    \n",
    "    Plot 2: The second subplot shows the eigenvalues on the complex plane. \n",
    "    Eigenvalues are plotted as dots, and the unit circle is drawn to indicate \n",
    "    the boundary between stable and unstable dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(\n",
    "        nrows=1, ncols=2, figsize=(12, 5), dpi=300)\n",
    "\n",
    "    # Plot Eigenspectrum\n",
    "\n",
    "    # Unit circle marks boundary for stability\n",
    "    \"\"\"\n",
    "    The unit circle in the eigenvalue plot marks the boundary for stability. \n",
    "    Eigenvalues inside this circle suggest contracting dynamics, which are associated \n",
    "    with stability.\n",
    "    \"\"\"\n",
    "    ax[1].set_title('Eigenvalues', fontsize=18)\n",
    "    xs = np.linspace(-1, 1, 1000)\n",
    "    ys = np.sqrt(1 - xs**2)\n",
    "    ax[1].plot(xs, ys,':k',linewidth = 1)\n",
    "    ax[1].plot(xs, -ys,':k',linewidth = 1)\n",
    "    \n",
    "    ### Eigenvalues within the unit circle correspond to contracting dimensions\n",
    "    ax[1].plot(\n",
    "        eig_decomps[0]['evals'].real, \n",
    "        eig_decomps[0]['evals'].imag,\n",
    "        '.k', \n",
    "        alpha = .3,\n",
    "        markerfacecolor = 'k'\n",
    "    )\n",
    "\n",
    "    # Eigenspectum labels\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax[1].set_xlabel('Real Part', fontsize=18)\n",
    "    ax[1].set_ylabel('Imaginary Part', fontsize=18)\n",
    "    # plt.xticks(fontsize = 18)\n",
    "    # plt.yticks(fontsize = 18)\n",
    "    ax[1].set_aspect('equal') \n",
    "    \n",
    "\n",
    "    ax[0].set_title(f'Fixed points for {condition}', fontsize=18)\n",
    "    \n",
    "    # Chose which PCs to plot\n",
    "    pc_x = 0\n",
    "    pc_y = 1\n",
    "    scatter = ax[0].scatter(\n",
    "        transformed_actor_hidden_states_training_set[:, :, pc_x],\n",
    "        transformed_actor_hidden_states_training_set[:, :, pc_y],\n",
    "        c=a1_probs_training_set, \n",
    "        cmap=cm.coolwarm,\n",
    "        vmin=0, vmax=1, \n",
    "        s=2, alpha=0.7\n",
    "    )\n",
    "\n",
    "    # PC axes labels\n",
    "    ax[0].set_xlabel(f'PC {pc_x+1}', fontsize=18)\n",
    "    ax[0].set_ylabel(f'PC {pc_y+1}', fontsize=18)\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "    # Colorbar label\n",
    "    cbar = fig.colorbar(scatter, ax=ax[0])\n",
    "    cbar.set_label('Probability \\n of Right Lick', rotation=0, labelpad=15, ha='center', va='top')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Plot Fixed Points\n",
    "    principal_components = pca_model_actor.components_\n",
    "    D_use = principal_components[[pc_x,pc_y],:].T\n",
    "    plot_FPs(ax[0],fixed_points, eig_decomps, D_use, plot_expansion = True, rf=2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee1181",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Contracting vs. Expanding Dimensions:** Eigenvalues reveal local stability:\n",
    "  - Magnitude **< 1**: Contracting, indicating stability.\n",
    "  - Magnitude **> 1**: Expanding, indicating instability.\n",
    "- **Practical Implications:** Identifies stable and unstable regions in the state space, crucial for understanding system behavior and robustness.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26c7fb0",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## 5. Stability Analysis Using Perturbation Analysis\n",
    "\n",
    "In the previous section, we calculated the stable and unstable dimensions of fixed points using linear stability analysis. In this section we will empirically calculate stability.\n",
    "\n",
    "**Objective:** Assess the stability of dynamics near fixed points by perturbation analysis, using Gaussian point clouds to observe how small perturbations in the network state around fixed points evolve over time.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. Create a small Gaussian cloud around each fixed point. This is a cloud of points generated from a normal distribution centered at the fixed point.\n",
    "\n",
    "2. Let the initial Gaussian cloud evolve according to the RNN dynamics. This simulates how small perturbations behave over time.\n",
    "\n",
    "3. Compare the distribution of points after evolution to determine stability. Points that cluster towards the fixed point indicate stability, while those moving away suggest instability.\n",
    "\n",
    "By following these steps, we evaluate the stability of fixed points and understand the system’s response to perturbations. We can also compare these results to the linear stability analysis in the previous section.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f54341",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Load precomputed initial and evolved point clouds:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The initial random points and the final points after evolution are pre-computed and provided\n",
    "# Here we have three different diameter for the initial Gaussian balls\n",
    "with open(f'./data/perturbation_0.05_init_points_dict.pickle', 'rb') as f:\n",
    "    init_points_dict_005 = pickle.load(f)\n",
    "with open(f'./data/perturbation_0.05_final_points_dict.pickle', 'rb') as f:\n",
    "    final_points_dict_005 = pickle.load(f)\n",
    "\n",
    "# with open(f'./data/perturbation_0.2_init_points_dict.pickle', 'rb') as f:\n",
    "#     init_points_dict_02 = pickle.load(f)\n",
    "# with open(f'./data/perturbation_0.2_final_points_dict.pickle', 'rb') as f:\n",
    "#     final_points_dict_02 = pickle.load(f)\n",
    "    \n",
    "# with open(f'./data/perturbation_0.5_init_points_dict.pickle', 'rb') as f:\n",
    "#     init_points_dict_05 = pickle.load(f)\n",
    "# with open(f'./data/perturbation_0.5_final_points_dict.pickle', 'rb') as f:\n",
    "#     final_points_dict_05 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef17e5",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "*Plot evolution of points initialized in a Gaussian cloud around fixed points: Initial points represented by gray circles and green circles for evolved points, showing the ball's trajectory from initialization to final state. Plot initial and final point clouds projected onto the first two PCs:*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67134f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian ball of 0.05\n",
    "init_points_dict = init_points_dict_005\n",
    "final_points_dict = final_points_dict_005\n",
    "\n",
    "for condition in ['0+', '0-', '1+', '1-', 'null']:\n",
    "\n",
    "    df_sorted = df_fps_per_condition[condition].sort_values(by=['q_star'], ascending=True)\n",
    "    df_select = df_sorted.iloc[:10]  # only plot the slowest 10 fps\n",
    "    \n",
    "    # transform fixed points\n",
    "    slowest_points = df_select['x_star'].values\n",
    "    slowest_points = np.vstack(slowest_points[:]).astype(float)  # convert object arr to float arr\n",
    "    slowest_points_mean = np.mean(slowest_points, axis=0)\n",
    "    transformed_slowest_points_mean = pca_model_actor.transform(\n",
    "        slowest_points_mean.reshape(-1, rnn_hidden_dim))\n",
    "    \n",
    "    # initialize a Gaussian ball near the slowest point\n",
    "    rand_init_points = init_points_dict[condition]  # load the pre-computed data\n",
    "    transformed_init_points = pca_model_actor.transform(\n",
    "        rand_init_points.reshape(-1, rnn_hidden_dim))\n",
    "    \n",
    "    # evolve the Gaussian ball\n",
    "    rand_final_points = final_points_dict[condition]  # load the pre-computed data\n",
    "    transformed_rand_final_points = pca_model_actor.transform(\n",
    "        rand_final_points.reshape(-1, rnn_hidden_dim))\n",
    "    \n",
    "    \n",
    "    # pldf_fps_per_condition[condition]ot fixed points and Gaussian ball evolution\n",
    "    fig, ax = plt.subplots(1,1, figsize=(5, 4.5), dpi=300)\n",
    "    pc_x = 0\n",
    "    pc_y = 1\n",
    "    ax.set_title(f'Fixed points for {condition}', fontsize=18)\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        transformed_actor_hidden_states_training_set[:, :, pc_x],\n",
    "        transformed_actor_hidden_states_training_set[:, :, pc_y],\n",
    "        c=a1_probs_training_set, cmap=cm.coolwarm,\n",
    "        vmin=0, vmax=1, s=3\n",
    "    )\n",
    "    ax.scatter(\n",
    "        transformed_slowest_points_mean[:, pc_x],\n",
    "        transformed_slowest_points_mean[:, pc_y],\n",
    "        marker='x', s=100,\n",
    "        color='k', zorder=50\n",
    "    )\n",
    "    ax.scatter(\n",
    "        transformed_init_points[:, pc_x],\n",
    "        transformed_init_points[:, pc_y],\n",
    "        marker='o', s=10,\n",
    "        color='darkgray', alpha=0.5\n",
    "    )\n",
    "    ax.scatter(\n",
    "        transformed_rand_final_points[:, pc_x],\n",
    "        transformed_rand_final_points[:, pc_y],\n",
    "        marker='o', s=10,\n",
    "        color='limegreen', alpha=0.5\n",
    "    )\n",
    "    ax.set_xlabel(f'PC {pc_x+1}', fontsize=18)\n",
    "    ax.set_ylabel(f'PC {pc_y+1}', fontsize=18)\n",
    "    \n",
    "    fig.colorbar(scatter, ax=ax)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1bafd2",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### Network solution utilizes a series of fixed points to drag the network state in a circle based on timing of block switches between the left and right rewarded arm.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3a3ad",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**Questions:**\n",
    "1. How does empirical stability compare with linear stability analysis results?\n",
    "2. How does this dynamical structure help the network have better policies than if it were continuously integrating?\n",
    "3. What would the dynamics look like if there was no block structure in the task?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e3a685",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf735ca0",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### Mathematical background for linear dynamical systems analysis\n",
    "From the supplementary information of Mante, V., Sussillo, D., Shenoy, K. et al. Context-dependent computation by recurrent dynamics in prefrontal cortex. Nature 503, 78–84 (2013). https://doi.org/10.1038/nature12742 [starting at page 26]\n",
    "\n",
    "#### Linear Systems\n",
    "\n",
    "Linear dynamical systems can do three basic things:\n",
    "1. Expand\n",
    "2. Contract\n",
    "3. Oscillate (or integrate)\n",
    "\n",
    "The primary method used to understand what a linear system is doing is by diagonalizing the interaction matrix, $M$, using an eigenvector decomposition. This decomposition is useful because it defines a basis in which certain patterns of activity, i.e. activity in special directions in state space, evolve separately from each other.\n",
    "\n",
    "A right eigenvector, $v$, satisfies:\n",
    "\n",
    "$$\n",
    "Mv = λv \n",
    "$$\n",
    "\n",
    "Thus, the matrix acts on these special vectors in a particularly straightforward way by scaling them by the amount $λ$, called the eigenvalue.\n",
    "\n",
    "So the behavior of a linear dynamical system:\n",
    "\n",
    "$$\n",
    "\\dot{y} = My\n",
    "$$\n",
    "\n",
    "which involves the repeated application of $M$, becomes easy to understand as, for example, the expansion (repeated scaling up) or contraction (repeated scaling down) of these vectors. \n",
    "\n",
    "#### Linearization\n",
    "Given a continuous-time nonlinear dynamical system\n",
    "$$\n",
    "\\dot{x} = F(x)\n",
    "$$\n",
    "with a fixed point $F(x^*)=0$, we can linearize its dynamics around the fixed point. \n",
    "It is convenient to introduce a new state variable as $y ≡ x-x^*$. \n",
    "The local dynamics is then described by the linear dynamical system of the form $\\dot{y} = M y$, where $M$ is the Jacobian matrix calculated at $x^*$.\n",
    "\n",
    "#### The eigenvectors are a property of the matrix\n",
    "\n",
    "The eigenvector decomposition is:\n",
    "\n",
    "\\begin{equation}\n",
    "M = REL = Σ_a r_a λ_a l_a,\n",
    "\\label{eq:M_REL}\n",
    "\\end{equation}\n",
    "\n",
    "where $λ_a$ is the $a$-th eigenvalue, $r_a$ is the $a$-th right eigenvector (a column of $R$) and $l_a$ is the $a$-th left eigenvector (a row of $L$). The matrix $R$ is the matrix of right eigenvectors collected as columns, $L$ is the matrix of left eigenvectors collected as rows with the property that $L = R^{-1}$. The matrix $E$ is a diagonal matrix of eigenvalues.†\n",
    "\n",
    "Looking forward, we are interested in the linearized dynamics around a fixed point in the full nonlinear system. To study those linear dynamics, we study $M$ that derives from the original nonlinear system. The way to make sense of $M$ is to use the eigenvector decomposition, defined by the equation above.\n",
    "\n",
    "#### Diagonalization of Discrete-Time Linear Dynamical Systems\n",
    "\n",
    "In the basis of the eigenvectors (*eigenbasis*), the local linear system is diagonalized, meaning the dynamics of all the modes evolve independently of each other. In the discrete time setting, diagonalizing the local network dynamics around a fixed point proceeds (again with $y ≡ x - x^*$) as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "y[t+1] = My[t]\n",
    "\\end{equation}\n",
    "\n",
    "where $M$ is the interaction matrix. We can decompose $M$ using eigenvectors:\n",
    "\n",
    "\\begin{equation}\n",
    "y[t+1] = (REL)y[t] \n",
    "\\end{equation}\n",
    "\n",
    "where $R$ is the matrix of right eigenvectors, $E$ is a diagonal matrix of eigenvalues, and $L = R^{-1}$ is the matrix of left eigenvectors.\n",
    "\n",
    "To diagonalize the system, we pre-multiply both sides by $L$:\n",
    "\n",
    "\\begin{equation}\n",
    "Ly[t+1] = E(Ly[t]) \n",
    "\\end{equation}\n",
    "\n",
    "This step works because:\n",
    "1. $L(REL) = (LR)EL = IEL = EL$, since $LR = I$\n",
    "2. We define $a[t] = Ly[t]$ as the system state in the eigenvector basis\n",
    "\n",
    "Now each mode evolves independently:\n",
    "\n",
    "\\begin{equation}\n",
    "a_i[t+1] = λ_i a_i[t]\n",
    "\\end{equation}\n",
    "\n",
    "where $λ_i$ is the $i$-th eigenvalue and $a_i$ is the $i$-th component of $a$.\n",
    "\n",
    "This diagonalization allows us to easily analyze the system's behavior in terms of expansion, contraction, oscillation for each eigenmode. Assuming all the eigenvalues are distinct, the linear dynamical system is trivially solved in this basis, giving:\n",
    "\n",
    "\\begin{equation}\n",
    "a_i[t] = (λ_i)^t a_i [0]\n",
    "\\end{equation}\n",
    "\n",
    "where $a_i [0]$ is the initial condition. The behavior of each mode depends on the magnitude of $λ_i$:\n",
    "\n",
    "1. $|λ_i| > 1$: The mode expands\n",
    "2. $|λ_i| < 1$: The mode contracts\n",
    "3. $|λ_i| = 1$: The mode oscillates or integrates\n",
    "\n",
    "For complex eigenvalues $λ_i = \\rho_i e^{iθ_i}$, the solution can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "a_i[t] = \\rho_i^{t}(cos(θ_i t) + i sin(θ_i t)) a_i[0] \n",
    "\\end{equation}\n",
    "\n",
    "where $\\rho_i$ determines the rate of expansion or contraction, and $θ_i$ determines the frequency of oscillation.\n",
    "\n",
    "---\n",
    "\n",
    "† A right eigenvector satisfies $M r_i = λ_i r_i$ and a left eigenvector satisfies $l_i M = λ_i l_i$.\n",
    "\n",
    "‡ Note that in the discrete-time setting, integration occurs when $λ_i = 1$. This is analogous to the continuous-time case where $λ_i = 0$.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f9a5e3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
